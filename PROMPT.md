# Job Hunter V2 - ETLç³»ç»Ÿæ„å»ºä»»åŠ¡

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ªèŒä½æ•°æ®ETLç³»ç»Ÿ,ä»å¤šä¸ªæ‹›è˜ç½‘ç«™çš„HTMLé¡µé¢ä¸­æå–èŒä½ä¿¡æ¯,å¹¶æŒ‰ç…§ç»Ÿä¸€çš„JSON Schemaè¾“å‡ºç»“æ„åŒ–æ•°æ®ã€‚

### æ ¸å¿ƒç›®æ ‡
1. **ä¸€ä¸ªç½‘ç«™ä¸€ä¸ªETLè„šæœ¬** - æ¯ä¸ªæ‹›è˜ç½‘ç«™å¯¹åº”ç‹¬ç«‹çš„ETLè„šæœ¬
2. **ç»Ÿä¸€æ•°æ®ç»“æ„** - æ‰€æœ‰è„šæœ¬è¾“å‡ºç¬¦åˆ `schema.json` å®šä¹‰çš„ `job_brief` ç»“æ„
3. **å¯æ‰©å±•æ¶æ„** - æ”¯æŒå¿«é€Ÿæ·»åŠ æ–°ç½‘ç«™çš„ETLè„šæœ¬
4. **ç”Ÿäº§çº§ä»£ç ** - éµå¾ªGoogle Python Style Guide,å¯ç»´æŠ¤ã€å¯æ‰©å±•

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
job-hunter-v2/
â”œâ”€â”€ schema.json              # æ•°æ®ç»“æ„å®šä¹‰
â”œâ”€â”€ example.py                   # å‚è€ƒç¤ºä¾‹ä»£ç 
â”œâ”€â”€ etl_template.py         # ETLè„šæœ¬æ¨¡æ¿
â”œâ”€â”€ etl_didi.py             # æ»´æ»´æ‹›è˜ETLè„šæœ¬
â”œâ”€â”€ etl_tencent.py          # è…¾è®¯æ‹›è˜ETLè„šæœ¬
â”œâ”€â”€ etl_xiaomi.py           # å°ç±³æ‹›è˜ETLè„šæœ¬
â”œâ”€â”€ etl_nio.py              # è”šæ¥æ‹›è˜ETLè„šæœ¬
â”œâ”€â”€ batch_etl.py            # æ‰¹é‡å¤„ç†è„šæœ¬
â”œâ”€â”€ test_etl.py             # æµ‹è¯•è„šæœ¬
â”œâ”€â”€ ds-didi/                # æ»´æ»´HTMLæ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ p-1.html
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ds-tencent/             # è…¾è®¯HTMLæ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ p-1.html
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ds-xiaomi/              # å°ç±³HTMLæ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ p-1.html
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ds-nio/                 # è”šæ¥HTMLæ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ p-1.html
â”‚   â””â”€â”€ ...
â””â”€â”€ output/                 # è¾“å‡ºç›®å½•
    â”œâ”€â”€ didi_jobs.json
    â”œâ”€â”€ tencent_jobs.json
    â”œâ”€â”€ xiaomi_jobs.json
    â”œâ”€â”€ nio_jobs.json
    â””â”€â”€ all_jobs.json
```

---

## ğŸ“Š æ•°æ®ç»“æ„è§„èŒƒ

### Schemaä½ç½®
`schema.json` - åŒ…å«å®Œæ•´çš„ `job_brief` æ•°æ®ç»“æ„å®šä¹‰

### å¿…éœ€å­—æ®µ (5ä¸ª)
```json
{
  "id": "string",              // èŒä½å”¯ä¸€æ ‡è¯†ç¬¦
  "site_id": "string",         // ç«™ç‚¹æ ‡è¯†ç¬¦ (å¦‚: "didi", "tencent")
  "title": "string",           // èŒä½æ ‡é¢˜
  "url": "string",             // èŒä½è¯¦æƒ…é¡µURL
  "posted_time": "string"      // å‘å¸ƒæ—¶é—´ (ISO 8601æ ¼å¼: YYYY-MM-DDTHH:MM:SS)
}
```

### å¯é€‰å­—æ®µ (9ä¸ª)
```json
{
  "company_name": "string",    // å…¬å¸åç§°
  "city": "string",            // å·¥ä½œåŸå¸‚
  "location_text": "string",   // å®Œæ•´ä½ç½®æ–‡æœ¬ (åŸå¸‚ã€åœ°åŒºã€å›½å®¶)
  "job_category": "string",    // èŒä½ç±»åˆ« (å¦‚: Engineering, Design, Product)
  "job_level": "string",       // èŒä½çº§åˆ« (å¦‚: Junior, Senior, Lead, Manager)
  "employment_type": "string", // é›‡ä½£ç±»å‹ (full-time, part-time, intern, contract)
  "work_mode": "string",       // å·¥ä½œæ¨¡å¼ (onsite, remote, hybrid)
  "salary_text": "string",     // è–ªèµ„èŒƒå›´æ–‡æœ¬
  "tags": ["string"],          // èŒä½æ ‡ç­¾æ•°ç»„
  "summary": "string",         // èŒä½æ‘˜è¦æˆ–æè¿°é¢„è§ˆ
  "discover_time": "string"    // å‘ç°æ—¶é—´ (ISO 8601æ ¼å¼)
}
```

---

## ğŸ› ï¸ æŠ€æœ¯è¦æ±‚

### ä»£ç è§„èŒƒ
- **Pythonç‰ˆæœ¬**: â‰¥3.10 (ä¼˜å…ˆ3.12+)
- **é£æ ¼æŒ‡å—**: Google Python Style Guide
- **ç±»å‹æ³¨è§£**: å…¨é‡ç±»å‹æ³¨è§£,å¤æ‚ç±»å‹ç”¨åŒå¼•å·åŒ…è£¹
- **å­—ç¬¦ä¸²**: ç»Ÿä¸€ä½¿ç”¨åŒå¼•å·
- **å¯¼å…¥**: `from pathlib import Path` (ä¸è¦ `import pathlib`)
- **æ–‡æ¡£å­—ç¬¦ä¸²**: Googleæˆ–NumPyé£æ ¼,ç®€æ´å®Œæ•´

### ä¾èµ–åº“
```python
from bs4 import BeautifulSoup    # HTMLè§£æ
from datetime import datetime     # æ—¶é—´å¤„ç†ï¼Œ æˆ–è€… `import datetime as dt`
from pathlib import Path          # è·¯å¾„æ“ä½œ
from typing import Any            # ç±»å‹æ³¨è§£
import json                       # JSONå¤„ç†
from cells.date.core import DateTimeParser  # å¤„ç†æ—¶é—´è§£æï¼Œä¸æ”¯æŒ ã€Œæ—¶é—´æˆ³ã€ï¼Œã€Œç›¸å¯¹æ—¶é—´ã€
```

### å¼‚å¸¸å¤„ç†
- æ˜¾å¼æ•è·å¼‚å¸¸,åˆ†ç±»æ¸…æ™°
- å•ä¸ªèŒä½è§£æå¤±è´¥ä¸å½±å“æ•´ä½“
- æä¾›æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯

---

## ğŸ“ å‚è€ƒæ–‡ä»¶è¯´æ˜

### 1. example.py - å‚è€ƒç¤ºä¾‹
```python
from bs4 import BeautifulSoup

with open("p-8.html", "r", encoding="utf-8") as f:
    c = f.read()
    soup = BeautifulSoup(c, "lxml")
    tags = soup.find_all(href=True)
    print([tag['href'] for tag in tags])
```

**å…³é”®è¦ç‚¹**:
- ä½¿ç”¨ `BeautifulSoup` è§£æHTML
- ä½¿ç”¨ `lxml` è§£æå™¨
- ä½¿ç”¨ `find_all()` æŸ¥æ‰¾å…ƒç´ 
- é€šè¿‡æ ‡ç­¾å±æ€§æå–æ•°æ®

### 2. etl_template.py - ETLæ¨¡æ¿
åŒ…å«å®Œæ•´çš„ETLè„šæœ¬ç»“æ„:
- `parse_job_brief()` - è§£æHTML,æå–èŒä½ä¿¡æ¯
- `save_to_json()` - ä¿å­˜ä¸ºJSONæ–‡ä»¶
- `etl()` - ä¸»æµç¨‹å‡½æ•°

---

## ğŸ¯ ETLè„šæœ¬ç¼–å†™è§„èŒƒ

### æ ¸å¿ƒå‡½æ•°ç»“æ„

#### 1. parse_job_brief() - è§£æå‡½æ•°
```python
def parse_job_brief(html_content: str, site_id: str) -> list[dict[str, Any]]:
    """
    è§£æHTMLå†…å®¹,æå–èŒä½ä¿¡æ¯
    
    Args:
        html_content: HTMLå­—ç¬¦ä¸²
        site_id: ç«™ç‚¹æ ‡è¯†ç¬¦
    
    Returns:
        èŒä½åˆ—è¡¨,æ¯ä¸ªèŒä½ç¬¦åˆjob_briefç»“æ„
    """
    soup = BeautifulSoup(html_content, "lxml")
    jobs = []
    
    # æ ¹æ®å…·ä½“ç½‘ç«™çš„HTMLç»“æ„å®ç°è§£æé€»è¾‘
    # 1. æ‰¾åˆ°æ‰€æœ‰èŒä½å¡ç‰‡/è¡Œ
    # 2. éå†æ¯ä¸ªèŒä½å…ƒç´ 
    # 3. æå–æ‰€æœ‰å¯ç”¨å­—æ®µ
    # 4. æ„å»ºjob_briefå­—å…¸
    # 5. æ·»åŠ åˆ°jobsåˆ—è¡¨
    
    return jobs
```

#### 2. save_to_json() - ä¿å­˜å‡½æ•°
```python
def save_to_json(jobs: list[dict[str, Any]], output_path: str) -> None:
    """
    å°†èŒä½æ•°æ®ä¿å­˜ä¸ºJSONæ–‡ä»¶
    
    Args:
        jobs: èŒä½åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(jobs, f, ensure_ascii=False, indent=2)
```

#### 3. etl() - ä¸»æµç¨‹å‡½æ•°
```python
def etl(html_file: str, output_json: str, site_id: str) -> None:
    """
    ETLä¸»æµç¨‹:è¯»å–HTML -> è§£æ -> å¯¼å‡ºJSON
    
    Args:
        html_file: è¾“å…¥HTMLæ–‡ä»¶è·¯å¾„
        output_json: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
        site_id: ç«™ç‚¹æ ‡è¯†ç¬¦
    """
    with open(html_file, "r", encoding="utf-8") as f:
        html_content = f.read()
    
    jobs = parse_job_brief(html_content, site_id)
    save_to_json(jobs, output_json)
    
    print(f"å·²è§£æ {len(jobs)} ä¸ªèŒä½,ä¿å­˜è‡³ {output_json}")
```

### æ•°æ®æå–ç­–ç•¥

#### å¸¸è§HTMLç»“æ„ç±»å‹

**ç±»å‹1: å¡ç‰‡å¼å¸ƒå±€ (å°ç±³ã€æ»´æ»´)**
```html
<div class="job-card">
  <a href="/job/12345">èŒä½æ ‡é¢˜</a>
  <span class="city">åŒ—äº¬</span>
  <span class="category">ç ”å‘</span>
  <span class="time">2024-01-15</span>
</div>
```

**ç±»å‹2: è¡¨æ ¼å¸ƒå±€ (è”šæ¥)**
```html
<table>
  <tbody>
    <tr>
      <td href="http://nio.jobs.feishu.cn/...">èŒä½æ ‡é¢˜</td>
      <td>èŒèƒ½åˆ†ç±»</td>
      <td>å·¥ä½œåœ°ç‚¹</td>
      <td>å‘å¸ƒæ—¶é—´</td>
    </tr>
  </tbody>
</table>
```

**ç±»å‹3: åˆ—è¡¨å¸ƒå±€ (è…¾è®¯)**
```html
<ul class="job-list">
  <li>
    <a href="/position/12345">èŒä½æ ‡é¢˜</a>
    <div class="meta">
      <span>åŒ—äº¬</span>
      <span>æŠ€æœ¯</span>
      <span>2024-01-15</span>
    </div>
  </li>
</ul>
```

#### å­—æ®µæå–æŠ€å·§

**IDæå–**:
- ä»URLä¸­æå–: `url.split("/")[-1]`
- ä»dataå±æ€§æå–: `card.get("data-id")`

**æ—¶é—´å¤„ç†**:
```python
# ç›¸å¯¹æ—¶é—´è½¬æ¢
def parse_relative_time(text: str) -> str:
    """è½¬æ¢ç›¸å¯¹æ—¶é—´ä¸ºISOæ ¼å¼"""
    if "å¤©å‰" in text:
        days = int(text.replace("å¤©å‰", ""))
        return (datetime.now() - timedelta(days=days)).isoformat()
    # å…¶ä»–æ—¶é—´æ ¼å¼...

# ç»å¯¹æ—¶é—´è½¬æ¢
def parse_absolute_time(text: str) -> str:
    """è½¬æ¢ç»å¯¹æ—¶é—´ä¸ºISOæ ¼å¼"""
    return datetime.strptime(text, "%Y-%m-%d").isoformat()

# ï¼ˆå¯é€‰ï¼‰å¢å¼ºç‰ˆæ—¶é—´è§£æå™¨
def parse_time_as_date(text: str) -> str:
    date_parser = DateTimeParser(time_str, dt_format=None)
    date_obj: "dt.datetime" = date_parser.format("%Y-%m-%d").isoformat()
```

**èŒä½çº§åˆ«æ¨æ–­**:
```python
def infer_job_level(title: str) -> str:
    """æ ¹æ®èŒä½æ ‡é¢˜æ¨æ–­çº§åˆ«"""
    if any(kw in title for kw in ["å®ä¹ ", "intern"]):
        return "intern"
    elif any(kw in title for kw in ["ä¸“å®¶", "æ¶æ„", "lead"]):
        return "expert"
    elif any(kw in title for kw in ["èµ„æ·±", "é«˜çº§", "senior"]):
        return "senior"
    # å…¶ä»–çº§åˆ«...
    return ""
```

---

## ğŸš€ æ‰§è¡Œæ­¥éª¤

### æ­¥éª¤1: åˆ†æHTMLç»“æ„
```bash
# ä½¿ç”¨è°ƒè¯•è„šæœ¬æŸ¥çœ‹HTMLç»“æ„
python debug_nio.py
```

**å…³é”®ç‚¹**:
- æ‰¾åˆ°èŒä½åˆ—è¡¨å®¹å™¨
- ç¡®å®šæ¯ä¸ªèŒä½çš„HTMLç»“æ„
- è¯†åˆ«å…³é”®å­—æ®µçš„ä½ç½®
- å¤„ç†å¤šé¡µé¢ç»“æ„

### æ­¥éª¤2: åˆ›å»ºETLè„šæœ¬
```bash
# å¤åˆ¶æ¨¡æ¿
cp etl_template.py etl_<site>.py

# ä¿®æ”¹è„šæœ¬
# 1. æ›´æ–°æ–‡ä»¶å¤´éƒ¨æ³¨é‡Š
# 2. å®ç°parse_job_brief()å‡½æ•°
# 3. æ·»åŠ è¾…åŠ©å‡½æ•°(æ—¶é—´è§£æã€çº§åˆ«æ¨æ–­ç­‰)
# 4. æ›´æ–°mainå‡½æ•°è°ƒç”¨
```

### æ­¥éª¤3: æµ‹è¯•ETLè„šæœ¬
```bash
# è¿è¡Œå•ä¸ªç½‘ç«™
python etl_<site>.py

# æ£€æŸ¥è¾“å‡º
cat output/<site>_jobs.json | head -20
```

### æ­¥éª¤4: é›†æˆåˆ°æ‰¹é‡å¤„ç†
```python
# åœ¨batch_etl.pyä¸­æ·»åŠ é…ç½®
SITE_CONFIG = {
    "<site>": {
        "name": "å…¬å¸åç§°",
        "html_dir": "ds-<site>",
        "output_file": "output/<site>_jobs.json",
        "site_id": "<site>",
        "etl_module": "etl_<site>",
        "etl_function": "etl",
        "max_pages": 5,
    },
    # ...
}
```

### æ­¥éª¤5: æ‰¹é‡è¿è¡Œ
```bash
# è¿è¡Œæ‰€æœ‰ç½‘ç«™
python batch_etl.py

# è¿è¡ŒæŒ‡å®šç½‘ç«™
python batch_etl.py --sites didi tencent
```

---

## âœ… éªŒè¯æ ‡å‡†

### ä»£ç è´¨é‡
- [ ] éµå¾ªGoogle Python Style Guide
- [ ] å®Œæ•´çš„ç±»å‹æ³¨è§£
- [ ] æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] å®Œå–„çš„å¼‚å¸¸å¤„ç†
- [ ] å¯è¯»çš„å˜é‡å‘½å

### æ•°æ®è´¨é‡
- [ ] æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
- [ ] æ—¶é—´æ ¼å¼ç¬¦åˆISO 8601æ ‡å‡†
- [ ] æšä¸¾å€¼åœ¨å…è®¸èŒƒå›´å†…
- [ ] æ— é‡å¤çš„èŒä½ID
- [ ] URLæ ¼å¼æ­£ç¡®

### åŠŸèƒ½å®Œæ•´æ€§
- [ ] èƒ½å¤Ÿè§£æHTMLæ–‡ä»¶
- [ ] èƒ½å¤Ÿæå–æ‰€æœ‰å¯ç”¨å­—æ®µ
- [ ] èƒ½å¤Ÿè¾“å‡ºJSONæ–‡ä»¶
- [ ] èƒ½å¤Ÿå¤„ç†å¤šé¡µé¢
- [ ] èƒ½å¤Ÿé›†æˆåˆ°æ‰¹é‡å¤„ç†

### è¾“å‡ºæ ¼å¼éªŒè¯
```bash
# éªŒè¯JSONæ ¼å¼
python -m json.tool output/<site>_jobs.json > /dev/null

# ç»Ÿè®¡èŒä½æ•°é‡
python -c "import json; data=json.load(open('output/<site>_jobs.json')); print(f'Total jobs: {len(data)}')"

# æ£€æŸ¥å¿…éœ€å­—æ®µ
python -c "
import json
data = json.load(open('output/<site>_jobs.json'))
required = ['id', 'site_id', 'title', 'url', 'posted_time']
for job in data:
    missing = [f for f in required if f not in job]
    if missing:
        print(f'Job {job.get(\"id\")} missing: {missing}')
"
```

---

## ğŸ“š ç¤ºä¾‹ç½‘ç«™

### å·²å®Œæˆçš„ETLè„šæœ¬

#### 1. æ»´æ»´ (etl_didi.py)
- **HTMLç»“æ„**: å¡ç‰‡å¼å¸ƒå±€
- **å…³é”®å…ƒç´ **: `div.job-card`
- **æå–å­—æ®µ**: éƒ¨é—¨ã€èŒä½ç±»å‹ã€åŸå¸‚ã€å‘å¸ƒæ—¶é—´
- **ç‰¹æ®Šå¤„ç†**: èŒä½çº§åˆ«æ¨æ–­ã€æ—¶é—´è§£æ

#### 2. è…¾è®¯ (etl_tencent.py)
- **HTMLç»“æ„**: åˆ—è¡¨å¼å¸ƒå±€
- **å…³é”®å…ƒç´ **: `ul.job-list > li`
- **æå–å­—æ®µ**: äº‹ä¸šç¾¤ã€èŒä½ç±»åˆ«ã€å·¥ä½œç»éªŒ
- **ç‰¹æ®Šå¤„ç†**: èŒä½çº§åˆ«æ¨æ–­ã€å¤šäº‹ä¸šç¾¤å¤„ç†

#### 3. å°ç±³ (etl_xiaomi.py)
- **HTMLç»“æ„**: å¡ç‰‡å¼å¸ƒå±€
- **å…³é”®å…ƒç´ **: `div.job-item`
- **æå–å­—æ®µ**: åŸå¸‚ã€æ‹›è˜ç±»å‹ã€é›‡ä½£ç±»å‹
- **ç‰¹æ®Šå¤„ç†**: å¤šé¡µé¢å¤„ç†ã€ç±»å‹æ ‡å‡†åŒ–

#### 4. è”šæ¥ (etl_nio.py)
- **HTMLç»“æ„**: è¡¨æ ¼å¼å¸ƒå±€
- **å…³é”®å…ƒç´ **: `table tbody tr`
- **æå–å­—æ®µ**: èŒèƒ½åˆ†ç±»ã€èŒèƒ½å­åˆ†ç±»ã€å·¥ä½œåœ°ç‚¹
- **ç‰¹æ®Šå¤„ç†**: è¡¨æ ¼è§£æã€IDæå–

---

## ğŸ”§ æ‰©å±•æ–°ç½‘ç«™

### å¿«é€Ÿæ·»åŠ æ–°ç½‘ç«™

#### 1. å‡†å¤‡HTMLæ•°æ®
```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir ds-<site>

# ä¸‹è½½HTMLæ–‡ä»¶
# å°†æ‹›è˜ç½‘ç«™çš„HTMLé¡µé¢ä¿å­˜åˆ° ds-<site>/p-1.html, p-2.html, ...
```

#### 2. åˆ†æHTMLç»“æ„
```python
# åˆ›å»ºä¸´æ—¶åˆ†æè„šæœ¬
from bs4 import BeautifulSoup

with open("ds-<site>/p-1.html", "r", encoding="utf-8") as f:
    soup = BeautifulSoup(f.read(), "lxml")

# æŸ¥æ‰¾èŒä½å…ƒç´ 
job_elements = soup.find_all("div", class_="job-card")
# æˆ–å…¶ä»–é€‰æ‹©å™¨...

# åˆ†æç¬¬ä¸€ä¸ªèŒä½çš„ç»“æ„
first_job = job_elements[0]
print(first_job.prettify())
```

#### 3. åˆ›å»ºETLè„šæœ¬
```bash
# å¤åˆ¶æ¨¡æ¿
cp etl_template.py etl_<site>.py

# ç¼–è¾‘è„šæœ¬
# 1. æ›´æ–°æ–‡ä»¶å¤´éƒ¨
# 2. å®ç°parse_job_brief()
# 3. æ·»åŠ è¾…åŠ©å‡½æ•°
# 4. æ›´æ–°mainå‡½æ•°
```

#### 4. æµ‹è¯•
```bash
# è¿è¡Œæµ‹è¯•
python etl_<site>.py

# éªŒè¯è¾“å‡º
cat output/<site>_jobs.json | jq '.[0]'
```

#### 5. é›†æˆ
```python
# åœ¨batch_etl.pyä¸­æ·»åŠ é…ç½®
SITE_CONFIG = {
    "<site>": {
        "name": "å…¬å¸åç§°",
        "html_dir": "ds-<site>",
        "output_file": "output/<site>_jobs.json",
        "site_id": "<site>",
        "etl_module": "etl_<site>",
        "etl_function": "etl",
        "max_pages": 5,
    },
}
```

---

## ğŸ“– æ–‡æ¡£æ”¯æŒ

### ä¸»è¦æ–‡æ¡£
- `README_ETL.md` - å®Œæ•´ä½¿ç”¨æ–‡æ¡£
- `QUICKSTART.md` - å¿«é€Ÿå¼€å§‹æŒ‡å—
- `ETL_SUMMARY.md` - é¡¹ç›®æ€»ç»“
- `PROMPT.md` - æœ¬æ–‡æ¡£(ä»»åŠ¡æ‰§è¡ŒæŒ‡å—)

### è„šæœ¬æ–‡æ¡£
- æ¯ä¸ªETLè„šæœ¬éƒ½åŒ…å«è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- å‡½æ•°çº§åˆ«çš„æ³¨é‡Šè¯´æ˜
- ä½¿ç”¨ç¤ºä¾‹

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### åŠŸèƒ½ç›®æ ‡
- âœ… è‡³å°‘å®Œæˆ3ä¸ªç½‘ç«™çš„ETLè„šæœ¬
- âœ… æ‰€æœ‰è„šæœ¬è¾“å‡ºç¬¦åˆschema.json
- âœ… æ”¯æŒæ‰¹é‡å¤„ç†
- âœ… ä»£ç å¯ç»´æŠ¤ã€å¯æ‰©å±•

### è´¨é‡ç›®æ ‡
- âœ… ä»£ç è¦†ç›–ç‡ > 80%
- âœ… æ‰€æœ‰å¿…éœ€å­—æ®µ100%å¡«å……
- âœ… æ—¶é—´æ ¼å¼100%æ­£ç¡®
- âœ… æ— é‡å¤èŒä½ID

### æ€§èƒ½ç›®æ ‡
- âœ… å•ä¸ªé¡µé¢è§£ææ—¶é—´ < 1ç§’
- âœ… æ‰¹é‡å¤„ç†10ä¸ªé¡µé¢ < 30ç§’
- âœ… å†…å­˜å ç”¨ < 500MB

---

## ğŸ“ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†ç¼ºå¤±å­—æ®µ?
A: æ ¹æ®schema.json,æŸäº›å­—æ®µæ˜¯å¯é€‰çš„ã€‚å¦‚æœæ— æ³•æå–,å¯ä»¥:
- è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸² `""`
- è®¾ç½®ä¸ºç©ºæ•°ç»„ `[]`
- æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­åˆç†çš„é»˜è®¤å€¼

### Q2: å¦‚ä½•å¤„ç†æ—¶é—´æ ¼å¼?
A: ä½¿ç”¨ISO 8601æ ¼å¼: `YYYY-MM-DDTHH:MM:SS`
- ç›¸å¯¹æ—¶é—´: è®¡ç®—ç»å¯¹æ—¶é—´
- ç»å¯¹æ—¶é—´: è½¬æ¢ä¸ºISOæ ¼å¼
- æœªçŸ¥æ—¶é—´: ä½¿ç”¨å½“å‰æ—¶é—´æˆ–ç•™ç©º

### Q3: å¦‚ä½•å¤„ç†å¤šé¡µé¢?
A: 
- æ–‡ä»¶å‘½å: `p-1.html`, `p-2.html`, ...
- æ‰¹é‡å¤„ç†: åœ¨ETLè„šæœ¬ä¸­å¾ªç¯å¤„ç†å¤šä¸ªæ–‡ä»¶
- æˆ–ä½¿ç”¨batch_etl.pyç»Ÿä¸€å¤„ç†

### Q4: å¦‚ä½•å¤„ç†å¼‚å¸¸?
A: ä½¿ç”¨try-exceptæ•è·å¼‚å¸¸,è®°å½•é”™è¯¯ä¿¡æ¯,ç»§ç»­å¤„ç†å…¶ä»–èŒä½:
```python
try:
    job = extract_job_info(element)
    jobs.append(job)
except Exception as e:
    print(f"è§£æèŒä½å¤±è´¥: {e}")
    continue
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. ä»£ç ç»„ç»‡
- å‡½æ•°å•ä¸€èŒè´£
- é¿å…è¿‡åº¦åµŒå¥—
- ä½¿ç”¨ç±»å‹æ³¨è§£
- æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²

### 2. æ•°æ®å¤„ç†
- ä¿ç•™ä¸­é—´å˜é‡
- é¿å…è¿‡åº¦åˆå¹¶
- æä¾›é»˜è®¤å€¼
- éªŒè¯æ•°æ®æ ¼å¼

### 3. é”™è¯¯å¤„ç†
- åˆ†ç±»æ•è·å¼‚å¸¸
- æä¾›æœ‰æ„ä¹‰çš„é”™è¯¯ä¿¡æ¯
- è®°å½•å¤±è´¥åŸå› 
- ä¸å½±å“æ•´ä½“æµç¨‹

### 4. æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨é«˜æ•ˆçš„CSSé€‰æ‹©å™¨
- é¿å…é‡å¤è§£æ
- æ‰¹é‡å¤„ç†æ•°æ®
- æ§åˆ¶å†…å­˜ä½¿ç”¨

---

## ğŸ“‹ ä»»åŠ¡æ¸…å•

### é˜¶æ®µ1: åŸºç¡€è®¾æ–½
- [x] åˆ›å»ºETLæ¨¡æ¿
- [x] å®šä¹‰æ•°æ®ç»“æ„
- [x] å»ºç«‹é¡¹ç›®ç»“æ„
- [x] ç¼–å†™æ‰¹é‡å¤„ç†è„šæœ¬

### é˜¶æ®µ2: ç½‘ç«™ETL
- [x] æ»´æ»´ETLè„šæœ¬
- [x] è…¾è®¯ETLè„šæœ¬
- [x] å°ç±³ETLè„šæœ¬
- [x] è”šæ¥ETLè„šæœ¬
- [ ] å¤§ç–†ETLè„šæœ¬
- [ ] ViperETLè„šæœ¬

### é˜¶æ®µ3: æµ‹è¯•éªŒè¯
- [x] å•å…ƒæµ‹è¯•
- [x] é›†æˆæµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•
- [ ] æ•°æ®è´¨é‡éªŒè¯

### é˜¶æ®µ4: æ–‡æ¡£å®Œå–„
- [x] ä½¿ç”¨æ–‡æ¡£
- [x] å¿«é€Ÿå¼€å§‹æŒ‡å—
- [x] ä»»åŠ¡æ‰§è¡ŒæŒ‡å—
- [ ] APIæ–‡æ¡£

---

## ğŸ‰ æ€»ç»“

æœ¬PROMPT.mdæä¾›äº†å®Œæ•´çš„ETLç³»ç»Ÿæ„å»ºæŒ‡å—,åŒ…æ‹¬:

1. **é¡¹ç›®èƒŒæ™¯å’Œç›®æ ‡** - æ˜ç¡®ä»»åŠ¡èŒƒå›´
2. **æ•°æ®ç»“æ„è§„èŒƒ** - ç»Ÿä¸€è¾“å‡ºæ ¼å¼
3. **æŠ€æœ¯è¦æ±‚** - ä»£ç è´¨é‡æ ‡å‡†
4. **å‚è€ƒæ–‡ä»¶è¯´æ˜** - å­¦ä¹ èµ„æº
5. **ETLè„šæœ¬ç¼–å†™è§„èŒƒ** - å®æ–½ç»†èŠ‚
6. **æ‰§è¡Œæ­¥éª¤** - å…·ä½“æ“ä½œæµç¨‹
7. **éªŒè¯æ ‡å‡†** - è´¨é‡æ£€æŸ¥
8. **æ‰©å±•æŒ‡å—** - æ·»åŠ æ–°ç½‘ç«™
9. **æœ€ä½³å®è·µ** - ç»éªŒæ€»ç»“

éµå¾ªæœ¬æŒ‡å—,å¯ä»¥å¿«é€Ÿæ„å»ºä¸€ä¸ªç”Ÿäº§çº§çš„èŒä½æ•°æ®ETLç³»ç»Ÿ!

---

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¶é—´**: 2025-01-15  
**ç»´æŠ¤è€…**: Job Hunter Team
